dataset	Weibo
category_num	2
save	ckpts/EANN_Text
use_preference_map	False
use_pattern_based_model	True
use_fact_based_model	False
num_gnn_layers	2
dim_node_features	768
updated_weights_for_A	0.5
pattern_based_model	EANN_Text
fact_based_model	
output_dim_of_pattern_based_model	256
output_dim_of_fact_based_model	0
num_mlp_layers	3
weight_of_normal_loss	1.0
weight_of_preference_loss	0.0
weight_of_reversed_loss	0.0
bilstm_input_max_sequence_length	100
bilstm_input_dim	768
bilstm_hidden_dim	128
bilstm_num_layer	1
bilstm_dropout	0
eann_input_max_sequence_length	100
eann_input_dim	768
eann_hidden_dim	64
eann_event_num	300
eann_use_textcnn	True
eann_weight_of_event_loss	1.0
bert_pretrained_model_chinese	bert-base-chinese
bert_pretrained_model_english	bert-base-uncased
bert_input_max_sequence_length	100
bert_training_embedding_layers	True
bert_training_inter_layers	True
bert_emotion_dim	0
bert_hidden_dim	768
mac_input_max_sequence_length	100
mac_max_doc_length	200
mac_input_dim	768
mac_hidden_dim	300
mac_dropout_doc	0
mac_dropout_query	0
mac_nhead_1	5
mac_nhead_2	2
evin_input_max_sequence_length	200
evin_max_doc_length	200
evin_input_dim	768
evin_hidden_dim	60
evin_dropout_att	0.5
evin_dropout_mlp	0.6
evin_nhead	6
declare_input_max_sequence_length	100
declare_input_dim	768
declare_hidden_dim	128
declare_max_doc_length	200
declare_bilstm_num_layer	1
declare_bilstm_dropout	0
lr	5e-05
epochs	50
batch_size	32
start_epoch	0
resume	
evaluate	False
debug	False
seed	9
device	cuda
fp16	True
local_rank	-1

PrefFEND(
  (PatternBasedModel): EANN_Text(
    (convs): ModuleList(
      (0): Conv2d(1, 20, kernel_size=(1, 768), stride=(1, 1))
      (1): Conv2d(1, 20, kernel_size=(2, 768), stride=(1, 1))
      (2): Conv2d(1, 20, kernel_size=(3, 768), stride=(1, 1))
      (3): Conv2d(1, 20, kernel_size=(4, 768), stride=(1, 1))
    )
    (fc_cnn): Linear(in_features=80, out_features=64, bias=True)
    (event_discriminator): Sequential(
      (0): Linear(in_features=64, out_features=64, bias=True)
      (1): LeakyReLU(negative_slope=True)
      (2): Linear(in_features=64, out_features=300, bias=True)
      (3): Softmax(dim=1)
    )
    (fake_news_detector): Sequential(
      (0): Linear(in_features=64, out_features=64, bias=True)
      (1): LeakyReLU(negative_slope=True)
      (2): Linear(in_features=64, out_features=256, bias=True)
    )
  )
  (fcs): ModuleList(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Linear(in_features=128, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
